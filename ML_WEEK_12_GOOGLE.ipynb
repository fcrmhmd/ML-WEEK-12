{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-WEEK-12-GOOGLE",
      "provenance": [],
      "authorship_tag": "ABX9TyNgcti81X2ydNJm6H/iia0w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcrmhmd/ML-WEEK-12/blob/main/ML_WEEK_12_GOOGLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzPmM_sWZxRn"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "metadata": {
        "id": "goJq9xsnaDYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the data directory\n",
        "data_dir = '../input/labelledrice/Labelled/'"
      ],
      "metadata": {
        "id": "kDNM-txNaDa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "images = glob(os.path.join(data_dir, '*/*.jpg'))\n",
        "tot_images = len(images)\n",
        "print('Total images:', tot_images)"
      ],
      "metadata": {
        "id": "IaZeu3C_aDdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_images = 3355\n",
        "im_cnt = []\n",
        "class_names = []\n",
        "print('{:18s}'.format('Class'), end='')\n",
        "print('Count')\n",
        "print('-' * 24)\n",
        "for folder in os.listdir(os.path.join(data_dir)):\n",
        "    folder_num = len(os.listdir(os.path.join(data_dir, folder)))\n",
        "    im_cnt.append(folder_num)\n",
        "    class_names.append(folder)\n",
        "    print('{:20s}'.format(folder), end=' ')\n",
        "    print(folder_num)\n",
        "    if (folder_num < tot_images):\n",
        "        tot_images = folder_num\n",
        "        folder_num = folder\n",
        "        \n",
        "num_classes = len(class_names)\n",
        "print('Total number of classes: {}'.format(num_classes))"
      ],
      "metadata": {
        "id": "jvJpPpP7aDgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for the training and validation sets\n",
        "data_transforms ={\n",
        "    \"train_transforms\": transforms.Compose([transforms.RandomRotation(30),\n",
        "                                           transforms.RandomResizedCrop(224), \n",
        "                                           transforms.RandomHorizontalFlip(), \n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize([0.485, 0.456, 0.406], \n",
        "                                                                [0.229, 0.224, 0.225])]),\n",
        "   \"valid_transforms\": transforms.Compose([transforms.Resize(225),\n",
        "                                           transforms.CenterCrop(224),\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                                [0.229, 0.224, 0.225])]), \n",
        "    \"test_transforms\": transforms.Compose([transforms.Resize(225),\n",
        "                                           transforms.CenterCrop(224),\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                                [0.229, 0.224, 0.225])])\n",
        "}"
      ],
      "metadata": {
        "id": "BhFafv51aDjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train, validation and test\n",
        "train_data = 0.8\n",
        "valid_data = 0.1\n",
        "test_data = 0.1\n",
        "\n",
        "# Load the datasets with ImageFolder\n",
        "train_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"train_transforms\"])#loading dataset\n",
        "valid_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"valid_transforms\"])\n",
        "test_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"test_transforms\"])\n",
        "\n",
        "# Obtain training indices that will be used for validation and test\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "# np.random.shuffle(indices)\n",
        "train_count = int(0.8*num_train)\n",
        "valid_count = int(0.1*num_train)\n",
        "test_count = num_train - train_count - valid_count\n",
        "train_idx = indices[:train_count]\n",
        "valid_idx = indices[train_count:train_count+valid_count]\n",
        "test_idx = indices[train_count+valid_count:]\n",
        "\n",
        "print(len(train_idx), len(valid_idx), len(test_idx))\n",
        "print(\"Training\", train_count, np.sum(len(train_idx)/num_train))\n",
        "print(\"Validation\", valid_count, np.sum(len(valid_idx)/num_train))\n",
        "print(\"Test\", test_count, np.sum(len(test_idx)/num_train))"
      ],
      "metadata": {
        "id": "b2lule6jaDmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom sampler for the dataset loader avoiding recreating the dataset (just creating a new loader for each different sampling)\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)"
      ],
      "metadata": {
        "id": "A930OqHPaDqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataloaders using the image datasets. Dataloader is used to load our data in batches\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
        "validloader = torch.utils.data.DataLoader(valid_data, batch_size = 32, sampler = valid_sampler)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size = 32, sampler = test_sampler)"
      ],
      "metadata": {
        "id": "pak-OscRaQ8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=['LeafBlast', 'BrownSpot', 'Healthy', 'Hispa']"
      ],
      "metadata": {
        "id": "DBWz-pgIaQ_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function to un-normalize and display an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 #unnormalize\n",
        "    plt.imshow(np.transpose(img, (1,2,0))) #convert tensor image type to numpy image type for visualization"
      ],
      "metadata": {
        "id": "MnySNsFxaRCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize some sample data\n",
        "#Obtain one batch of training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() #convert images to numpy for display\n",
        "\n",
        "#Plot the images in the batch, along with corresponding labels\n",
        "fig = plt.figure(figsize=(25,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "    #ax.set_title(str(labels[idx].item()))\n",
        "    ax.set_title(classes[labels[idx]])"
      ],
      "metadata": {
        "id": "UHC3Tk5vaRFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify model architecture\n",
        "# Load the pretrained model from pytorch's library and stored it in model_transfer\n",
        "model_transfer = models.googlenet(pretrained=True)\n",
        "\n",
        "# Check if GPU is available\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model_transfer = model_transfer.cuda()"
      ],
      "metadata": {
        "id": "Bfz0WN2paRI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the model to see all the layers\n",
        "print(model_transfer)"
      ],
      "metadata": {
        "id": "KmuEI_DxaRMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets read the fully connected layer\n",
        "print(model_transfer.fc.in_features)\n",
        "print(model_transfer.fc.out_features)"
      ],
      "metadata": {
        "id": "TZx5FbiMaRP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad=True"
      ],
      "metadata": {
        "id": "aPKK7IYbae68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define n_inputs takes the same number of inputs from pre-trained model\n",
        "n_inputs = model_transfer.fc.in_features #refer to the fully connected layer only\n",
        "\n",
        "# Add last linear layer (n_inputs -> 4 classes). In this case the ouput is 4 classes\n",
        "# New layer automatically has requires_grad = True\n",
        "last_layer = nn.Linear(n_inputs, len(classes))\n",
        "\n",
        "model_transfer.fc = last_layer\n",
        "\n",
        "# If GPU is available, move the model to GPU\n",
        "if use_cuda:\n",
        "    model_transfer = model_transfer.cuda()\n",
        "  \n",
        "# Check to see the last layer produces the expected number of outputs\n",
        "print(model_transfer.fc.out_features)"
      ],
      "metadata": {
        "id": "N2epVvjzae-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify loss function and optimizer\n",
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.SGD(model_transfer.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "FoMPX0yoafDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    '''returns trained model'''\n",
        "    # Initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.inf\n",
        "  \n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # In the training loop, I track down the loss\n",
        "        # Initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "    \n",
        "        # Model training\n",
        "        model.train()\n",
        "        for batch_idx, (data,target) in enumerate(trainloader):\n",
        "            # 1st step: Move to GPU\n",
        "            if use_cuda:\n",
        "                data,target = data.cuda(), target.cuda()\n",
        "      \n",
        "            # Then, clear (zero out) the gradient of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # Perform the Cross Entropy Loss. Calculate the batch loss.\n",
        "            loss = criterion(output, target)\n",
        "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # Perform optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # Record the average training loss\n",
        "            train_loss = train_loss + ((1/ (batch_idx + 1 ))*(loss.data-train_loss))\n",
        "      \n",
        "        # Model validation\n",
        "        model.eval()\n",
        "        for batch_idx, (data,target) in enumerate(validloader):\n",
        "            # Move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # Update the average validation loss\n",
        "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # Calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # Update the average validation loss\n",
        "            valid_loss = valid_loss + ((1/ (batch_idx +1)) * (loss.data - valid_loss))\n",
        "      \n",
        "        # print training/validation stats\n",
        "        print('Epoch: {} \\tTraining Loss: {:.5f} \\tValidation Loss: {:.5f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss))\n",
        "    \n",
        "        # Save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.5f} --> {:.5f}). Saving model ...'.format(\n",
        "                  valid_loss_min,\n",
        "                  valid_loss))\n",
        "            torch.save(model.state_dict(), 'model_transfer.pt')\n",
        "            valid_loss_min = valid_loss\n",
        "  \n",
        "    # Return trained model\n",
        "    return model\n",
        "\n",
        "# Define loaders transfer\n",
        "loaders_transfer = {'train': trainloader,\n",
        "                    'valid': validloader,\n",
        "                    'test': testloader}\n",
        "\n",
        "# Train the model\n",
        "model_transfer = train(50, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')"
      ],
      "metadata": {
        "id": "VNXjZezjaoOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model that got the best validation accuracy\n",
        "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
      ],
      "metadata": {
        "id": "Q5pH8WXFaoSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model_transfer.eval() #set model into evaluation/testing mode. It turns of drop off layer\n",
        "    #Iterating over test data\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to \n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
      ],
      "metadata": {
        "id": "P9fAYf-2aoWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain one batch of test images\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "images.numpy\n",
        "\n",
        "#Move model inputs to cuda, if GPU available\n",
        "if use_cuda:\n",
        "    images = images.cuda()\n",
        "    \n",
        "#Get sample outputs\n",
        "output= model_transfer(images)\n",
        "\n",
        "#Convert output probabilities to predicted class\n",
        "_,preds_tensor = torch.max(output,1)\n",
        "preds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
        "\n",
        "#Plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(30,4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(np.transpose(images.cpu()[idx], (1,2,0)))\n",
        "    ax.set_title(\"{} ({})\".format(classes[preds[idx]],classes[labels[idx]]),\n",
        "                color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
      ],
      "metadata": {
        "id": "y8GA9_2AavkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2h3ADsrmavyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uneL8QYvav49"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}